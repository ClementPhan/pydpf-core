{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Connect workflows on different processes implicitly {#ref_distributed_workflows_on_remote}\r\n\r\nThis example shows how distributed files can be read and post processed\r\non distributed processes. After remote post processing, results a merged\r\non the local process. In this example, different workflows are directly\r\ncreated on different servers. Those workflows are then connected\r\ntogether without having to care that they are on remote processes.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import dpf module and its examples files\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from ansys.dpf import core as dpf\nfrom ansys.dpf.core import examples\nfrom ansys.dpf.core import operators as ops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Configure the servers\r\n\r\nTo make this example easier, we will start local servers here, but we\r\ncould get connected to any existing servers on the network.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "remote_servers = [dpf.start_local_server(as_global=False), dpf.start_local_server(as_global=False)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create template workflows on remote servers\r\n\r\nFor the purpose of this example, we will create 2 workflows computing\r\nelemental nodal stresses on different servers. The second workflow will\r\nmultiply by 2.0 the stresses. A last workflow will merge the outputs\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "files = examples.download_distributed_files()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "first workflow S\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "workflow1 = dpf.Workflow(server=remote_servers[0])\nmodel = dpf.Model(files[0], server=remote_servers[0])\nstress1 = model.results.stress()\nworkflow1.add_operator(stress1)\nworkflow1.set_output_name(\"out1\", stress1.outputs.fields_container)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "second workflow S\\*2.0\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "workflow2 = dpf.Workflow(server=remote_servers[1])\nmodel = dpf.Model(files[1], server=remote_servers[1])\nstress2 = model.results.stress()\nmul = stress2 * 2.0\nworkflow2.add_operator(mul)\nworkflow2.set_output_name(\"out2\", mul.outputs.fields_container)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "third workflow merge\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "local_workflow = dpf.Workflow()\nmerge = ops.utility.merge_fields_containers()\nnodal = ops.averaging.to_nodal_fc(merge)\nlocal_workflow.add_operators([merge, nodal])\nlocal_workflow.set_input_name(\"in1\", merge, 0)\nlocal_workflow.set_input_name(\"in2\", merge, 1)\nlocal_workflow.set_output_name(\"merged\", nodal.outputs.fields_container)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Connect the workflows together and get the output\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "local_workflow.connect_with(workflow1, (\"out1\", \"in1\"))\nlocal_workflow.connect_with(workflow2, (\"out2\", \"in2\"))\n\nfc = local_workflow.get_output(\"merged\", dpf.types.fields_container)\nfc[0].meshed_region.plot(fc[0])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}