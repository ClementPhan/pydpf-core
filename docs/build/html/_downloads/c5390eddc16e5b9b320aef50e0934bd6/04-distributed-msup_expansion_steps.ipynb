{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Distributed msup distributed modal response {#ref_distributed_msup_steps}\r\n\r\nThis example shows how distributed files can be read and expanded on\r\ndistributed processes. The modal basis (2 distributed files) is read on\r\n2 remote servers and the modal response (2 distributed files) reading\r\nand the expansion is done on a third server.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import dpf module and its examples files\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os.path\n\nfrom ansys.dpf import core as dpf\nfrom ansys.dpf.core import examples\nfrom ansys.dpf.core import operators as ops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create the template workflow\r\n\r\nthis workflow will provide the modal basis and the mesh for each domain\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "template_workflow = dpf.Workflow()\ndisplacement = ops.result.displacement()\nmesh = ops.mesh.mesh_provider()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Add the operators to the template workflow and name its inputs and\r\noutputs Once workflow\\'s inputs and outputs are named, they can be\r\nconnected later on\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "template_workflow.add_operators([displacement])\ntemplate_workflow.set_input_name(\"data_sources\", displacement.inputs.data_sources)\ntemplate_workflow.set_input_name(\"data_sources\", mesh.inputs.data_sources)\ntemplate_workflow.set_output_name(\"out\", displacement.outputs.fields_container)\ntemplate_workflow.set_output_name(\"outmesh\", mesh.outputs.mesh)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Configure the servers\r\n\r\nMake a list of ip addresses an port numbers on which dpf servers are\r\nstarted. Workflows instances will be created on each of those servers to\r\naddress each a different result file. In this example, we will post\r\nprocess an analysis distributed in 2 files, we will consequently require\r\n2 remote processes To make this example easier, we will start local\r\nservers here, but we could get connected to any existing servers on the\r\nnetwork.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "remote_servers = [dpf.start_local_server(as_global=False), dpf.start_local_server(as_global=False)]\nips = [remote_server.ip for remote_server in remote_servers]\nports = [remote_server.port for remote_server in remote_servers]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Print the ips and ports\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"ips:\", ips)\nprint(\"ports:\", ports)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Choose the file path\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "base_path = examples.distributed_msup_folder\nfiles = [os.path.join(base_path, \"file0.mode\"), os.path.join(base_path, \"file1.mode\")]\nfiles_aux = [os.path.join(base_path, \"file0.rst\"), os.path.join(base_path, \"file1.rst\")]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Send workflows on servers\r\n\r\nHere we create new instances on the server by copies of the template\r\nworkflow We also connect the data sources to those workflows\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "remote_workflows = []\nfor i, server in enumerate(remote_servers):\n    remote_workflows.append(template_workflow.create_on_other_server(server))\n    ds = dpf.DataSources(files[i])\n    ds.add_file_path(files_aux[i])\n    remote_workflows[i].connect(\"data_sources\", ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create a local workflow for expansion\r\n\r\nIn this workflow we merge the modal basis, the meshes, read the modal\r\nresponse and expand the modal response with the modal basis\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "local_workflow = dpf.Workflow()\nmerge = ops.utility.merge_fields_containers()\nmerge_mesh = ops.utility.merge_meshes()\n\nds = dpf.DataSources(os.path.join(base_path, \"file_load_1.rfrq\"))\nresponse = ops.result.displacement(data_sources=ds)\nresponse.inputs.mesh(merge_mesh.outputs.merges_mesh)\n\nds = dpf.DataSources(os.path.join(base_path, \"file_load_2.rfrq\"))\nfrom os import walk\n\nfor (dirpath, dirnames, filenames) in walk(base_path):\n    print(filenames)\nresponse2 = ops.result.displacement(data_sources=ds)\nresponse2fc = response2.outputs.fields_container()\nresponse2fc.time_freq_support.time_frequencies.scoping.set_id(0, 2)\n\nmerge_use_pass = ops.utility.merge_fields_containers()\nmerge_use_pass.inputs.fields_containers1(response)\nmerge_use_pass.inputs.fields_containers2(response2fc)\n\nexpansion = ops.math.modal_superposition(solution_in_modal_space=merge_use_pass, modal_basis=merge)\ncomponent = ops.logic.component_selector_fc(expansion, 1)\n\nlocal_workflow.add_operators([merge, merge_use_pass, expansion, merge_mesh, component])\nlocal_workflow.set_input_name(\"in0\", merge, 0)\nlocal_workflow.set_input_name(\"in1\", merge, 1)\nlocal_workflow.set_input_name(\"inmesh0\", merge_mesh, 0)\nlocal_workflow.set_input_name(\"inmesh1\", merge_mesh, 1)\n\nlocal_workflow.set_output_name(\"expanded\", component.outputs.fields_container)\nlocal_workflow.set_output_name(\"mesh\", merge_mesh.outputs.merges_mesh)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Connect the workflows together and get the output\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for i, server in enumerate(remote_servers):\n    local_workflow.connect_with(remote_workflows[i],\n                                {\"out\": \"in\" + str(i), \"outmesh\": \"inmesh\" + str(i)})\n\nfc = local_workflow.get_output(\"expanded\", dpf.types.fields_container)\nmerged_mesh = local_workflow.get_output(\"mesh\", dpf.types.meshed_region)\nmerged_mesh.plot(fc.get_field_by_time_complex_ids(1, 0))\nmerged_mesh.plot(fc.get_field_by_time_complex_ids(20, 0))\nprint(fc)\ndpf.server.shutdown_all_session_servers()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}